{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caf6fa07",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Urban-Informatics-and-Visualization\" data-toc-modified-id=\"Urban-Informatics-and-Visualization-0.1\">Urban Informatics and Visualization</a></span></li></ul></li><li><span><a href=\"#2.1-Motivating-Example:-&quot;Brute-Force&quot;-Data-Analysis-in-Python\" data-toc-modified-id=\"2.1-Motivating-Example:-&quot;Brute-Force&quot;-Data-Analysis-in-Python-1\">2.1 Motivating Example: \"Brute Force\" Data Analysis in Python</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1.1-Row-based-iteration\" data-toc-modified-id=\"2.1.1-Row-based-iteration-1.1\">2.1.1 Row-based iteration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Thought-experiment:\" data-toc-modified-id=\"Thought-experiment:-1.1.1\">Thought experiment:</a></span></li></ul></li><li><span><a href=\"#2.1.2-List-based-iteration\" data-toc-modified-id=\"2.1.2-List-based-iteration-1.2\">2.1.2 List-based iteration</a></span></li><li><span><a href=\"#2.1.3-Vectorization:-an-Alternative-to-Iteration\" data-toc-modified-id=\"2.1.3-Vectorization:-an-Alternative-to-Iteration-1.3\">2.1.3 Vectorization: an Alternative to Iteration</a></span></li></ul></li><li><span><a href=\"#2.2-The-Python-Scientific-Stack\" data-toc-modified-id=\"2.2-The-Python-Scientific-Stack-2\">2.2 The Python Scientific Stack</a></span></li><li><span><a href=\"#2.3-NumPy-Arrays\" data-toc-modified-id=\"2.3-NumPy-Arrays-3\">2.3 NumPy Arrays</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.3.1-Install-vs-Import\" data-toc-modified-id=\"2.3.1-Install-vs-Import-3.1\">2.3.1 Install vs Import</a></span></li><li><span><a href=\"#2.3.2-Arrays-vs.-Lists\" data-toc-modified-id=\"2.3.2-Arrays-vs.-Lists-3.2\">2.3.2 Arrays vs. Lists</a></span></li><li><span><a href=\"#2.3.3-Working-with-Arrays\" data-toc-modified-id=\"2.3.3-Working-with-Arrays-3.3\">2.3.3 Working with Arrays</a></span></li><li><span><a href=\"#2.3.4-Numpy-for-Linear-Algebra\" data-toc-modified-id=\"2.3.4-Numpy-for-Linear-Algebra-3.4\">2.3.4 Numpy for Linear Algebra</a></span></li><li><span><a href=\"#2.3.5-Numpy-Summary\" data-toc-modified-id=\"2.3.5-Numpy-Summary-3.5\">2.3.5 Numpy Summary</a></span></li><li><span><a href=\"#2.3.6-Exercise\" data-toc-modified-id=\"2.3.6-Exercise-3.6\">2.3.6 Exercise</a></span></li></ul></li><li><span><a href=\"#2.4-Graphing-with-matplotlib\" data-toc-modified-id=\"2.4-Graphing-with-matplotlib-4\">2.4 Graphing with <code>matplotlib</code></a></span></li><li><span><a href=\"#2.5-Intro-to-pandas\" data-toc-modified-id=\"2.5-Intro-to-pandas-5\">2.5 Intro to pandas</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.5.1-The-pandas-data-types\" data-toc-modified-id=\"2.5.1-The-pandas-data-types-5.1\">2.5.1 The <code>pandas</code> data types</a></span></li><li><span><a href=\"#2.5.2-Importing-data\" data-toc-modified-id=\"2.5.2-Importing-data-5.2\">2.5.2 Importing data</a></span></li><li><span><a href=\"#2.5.3-Slicing-and-Selecting-Data\" data-toc-modified-id=\"2.5.3-Slicing-and-Selecting-Data-5.3\">2.5.3 Slicing and Selecting Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.5.3.1-Indexing\" data-toc-modified-id=\"2.5.3.1-Indexing-5.3.1\">2.5.3.1 Indexing</a></span></li><li><span><a href=\"#2.5.3.2-Boolean-Indexing\" data-toc-modified-id=\"2.5.3.2-Boolean-Indexing-5.3.2\">2.5.3.2 Boolean Indexing</a></span></li></ul></li><li><span><a href=\"#2.5.4-String-functions\" data-toc-modified-id=\"2.5.4-String-functions-5.4\">2.5.4 String functions</a></span></li><li><span><a href=\"#2.5.5-More-pandas-operations\" data-toc-modified-id=\"2.5.5-More-pandas-operations-5.5\">2.5.5 More pandas operations</a></span></li></ul></li><li><span><a href=\"#2.6-Exercises\" data-toc-modified-id=\"2.6-Exercises-6\">2.6 Exercises</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.6.1-Pandas-expressions\" data-toc-modified-id=\"2.6.1-Pandas-expressions-6.1\">2.6.1 Pandas expressions</a></span></li><li><span><a href=\"#2.6.2-COVID-cases-from-NY-Times\" data-toc-modified-id=\"2.6.2-COVID-cases-from-NY-Times-6.2\">2.6.2 COVID cases from NY Times</a></span></li></ul></li><li><span><a href=\"#3.-Intro-to-Data-Analysis\" data-toc-modified-id=\"3.-Intro-to-Data-Analysis-7\">3. Intro to Data Analysis</a></span></li><li><span><a href=\"#3.1-Merges-and-Joins\" data-toc-modified-id=\"3.1-Merges-and-Joins-8\">3.1 Merges and Joins</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1.1-Merge\" data-toc-modified-id=\"3.1.1-Merge-8.1\">3.1.1 Merge</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1.1.1-Inner-merge\" data-toc-modified-id=\"3.1.1.1-Inner-merge-8.1.1\">3.1.1.1 Inner merge</a></span></li><li><span><a href=\"#3.1.1.2-Left-merge\" data-toc-modified-id=\"3.1.1.2-Left-merge-8.1.2\">3.1.1.2 Left merge</a></span></li><li><span><a href=\"#3.1.1.3-Outer-Merge\" data-toc-modified-id=\"3.1.1.3-Outer-Merge-8.1.3\">3.1.1.3 Outer Merge</a></span></li></ul></li><li><span><a href=\"#3.1.2-Join\" data-toc-modified-id=\"3.1.2-Join-8.2\">3.1.2 Join</a></span></li><li><span><a href=\"#3.1.3-More-resources-to-learn-about-merges-and-joins\" data-toc-modified-id=\"3.1.3-More-resources-to-learn-about-merges-and-joins-8.3\">3.1.3 More resources to learn about merges and joins</a></span></li></ul></li><li><span><a href=\"#3.2-Using-Merge-and-str-ops-on-Real-Data\" data-toc-modified-id=\"3.2-Using-Merge-and-str-ops-on-Real-Data-9\">3.2 Using Merge and <code>str</code> ops on Real Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.2.1-Importing-County-level-Census-Data-for-the-U.S.\" data-toc-modified-id=\"3.2.1-Importing-County-level-Census-Data-for-the-U.S.-9.1\">3.2.1 Importing County level Census Data for the U.S.</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.2.1.1-A-note-on-character-encodings\" data-toc-modified-id=\"3.2.1.1-A-note-on-character-encodings-9.1.1\">3.2.1.1 A note on character encodings</a></span></li></ul></li><li><span><a href=\"#3.2.2-Data-Exploration-and-Cleaning\" data-toc-modified-id=\"3.2.2-Data-Exploration-and-Cleaning-9.2\">3.2.2 Data Exploration and Cleaning</a></span></li><li><span><a href=\"#3.2.3-Merging\" data-toc-modified-id=\"3.2.3-Merging-9.3\">3.2.3 Merging</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.2.3.1-Dealing-with-duplicate-columns\" data-toc-modified-id=\"3.2.3.1-Dealing-with-duplicate-columns-9.3.1\">3.2.3.1 Dealing with duplicate columns</a></span></li></ul></li></ul></li><li><span><a href=\"#3.3-More-Data-Exploration-and-Cleaning:-Berkeley-PD-Calls\" data-toc-modified-id=\"3.3-More-Data-Exploration-and-Cleaning:-Berkeley-PD-Calls-10\">3.3 More Data Exploration and Cleaning: Berkeley PD Calls</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.3.1-Preliminary-observations-on-the-data?\" data-toc-modified-id=\"3.3.1-Preliminary-observations-on-the-data?-10.1\">3.3.1 Preliminary observations on the data?</a></span></li><li><span><a href=\"#3.3.2-Data-analysis\" data-toc-modified-id=\"3.3.2-Data-analysis-10.2\">3.3.2 Data analysis</a></span></li><li><span><a href=\"#3.3.3-Datetime-operations\" data-toc-modified-id=\"3.3.3-Datetime-operations-10.3\">3.3.3 Datetime operations</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40ef5a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CYPLAN255\n",
    "### Urban Informatics and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc2c5d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "HIT RECORD and TRANSCRIBE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceea7a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 07 -- Scientific Computing in Python\n",
    "*******\n",
    "February 14, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7d376",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agenda\n",
    "1. Announcements\n",
    "2. Scientific Computing in Python\n",
    "3. Intro to Data Analysis\n",
    "4. For next time\n",
    "5. Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c0cef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Announcements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d336f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Assignment 2 due Tuesday\n",
    "2. Assignment 1 redemption opportunity (thank Irene)\n",
    "3. Syllabus updated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b61f31",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Scientific Computing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b134d6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " _\"Scientific computing is the collection of **tools**, **techniques**, and **theories** required to solve on a computer **mathematical models** of **problems in Science and Engineering**\"_\n",
    "\n",
    "<p style='text-align: right;'>-- Gene H. Golub and James M. Ortega. <br><i>Scientific Computing and Differential Equations â€“ An Introduction to Numerical Methods</i>. Academic Press, 1992.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f046415",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.1 Motivating Example: \"Brute Force\" Data Analysis in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab587ac",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's use the methods we learned to iterate through the rows of a file in order to process each row, one at a time.  We will load it via the `csv` library and open the file and iterate through the rows to compute the `mean`, `max`, and `min` values of rainfall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1687bf32",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.1.1 Row-based iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95e66932",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 3.7 inches\n",
      "max: 5.9 inches\n",
      "min: 0.7 inches\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('data/rain.csv', 'r') as csvfile:  # this is how you open a file in Python\n",
    "    \n",
    "    # initialize a counter and variables to contain our descriptive stats\n",
    "    count = 0  # at the end, divide cumulative_sum by this to get the mean\n",
    "    cumulative_sum = 0  # initialize another counter as the aggregate sum\n",
    "    max_value = -1  # pick a really small number that's guaranteed to be less than the actual max so that when there's a larger value the max automatically updates\n",
    "    min_value = 1000\n",
    "    \n",
    "    # open the file and skip the header row\n",
    "    my_csv = csv.reader(csvfile)\n",
    "    next(my_csv)\n",
    "    \n",
    "    # loop through each data row\n",
    "    for row in my_csv:\n",
    "        \n",
    "        # rainfall amount is in column 1, only process this row's value if not an empty string\n",
    "        if not row[1] == '':\n",
    "            \n",
    "            # increment the counter and extract this row's rainfall as a float\n",
    "            count = count + 1\n",
    "            rainfall = float(row[1])\n",
    "            \n",
    "            # add this row's rainfall to the cumulative sum\n",
    "            cumulative_sum = cumulative_sum + rainfall\n",
    "            \n",
    "            # UPDATE MAX: if this row's rainfall is greater than the current max value, update with the new max\n",
    "            if rainfall > max_value:\n",
    "                max_value = rainfall\n",
    "\n",
    "            # UPDATE MIN: if this row's rainfall is less than the current min value, update with the new min    \n",
    "            if rainfall < min_value:\n",
    "                min_value = rainfall\n",
    "\n",
    "    # after looping through all the rows, divide the cumulative sum by the count and round to get the mean\n",
    "    mean_value = round(cumulative_sum / count, 1)\n",
    "    \n",
    "    # print out the mean and max values\n",
    "    print('mean:', mean_value, 'inches')\n",
    "    print('max:', max_value, 'inches')\n",
    "    print('min:', min_value, 'inches')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf9a63a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Thought experiment: \n",
    "Can you think of a straightforward way to get the median value of rainfall?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db63511",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.1.2 List-based iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4611322e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Some things that are hard in the row-based iteration approach above become easier if we can keep store all of the values in one object, like a list.\n",
    "\n",
    "Let's try to reimplement a cleaner version of what we did above by appending the values from each row into a single list, and then performing the calculations we want on the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f1220d9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/rain.csv', 'r') as csvfile:\n",
    "    x = []\n",
    "    itemreader = csv.reader(csvfile)\n",
    "    # Skip the header row\n",
    "    next(itemreader)\n",
    "    for row in itemreader:\n",
    "        # keep only non-missing values\n",
    "        if row[1] != '':\n",
    "            x.append(float(row[1]))\n",
    "\n",
    "# convert each row to an item in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9da80c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.3, 5.4, 4.8, 4.7, 3.3, 1.2, 0.8, 0.7, 3.9, 4.5, 5.9]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369b3af0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "X is now a single list object with all the values in the file, whereas initially we just had each row producing one list with one element in it (from one row), and then printing that, before recreating it with the value from the next row.  The iteration approach kept only one row at a time, and we could not easily do calculations like a median.\n",
    "\n",
    "Using the list (x), we should now have an easier time with mean and median calculations, using list methods like sum and len, and sort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70be0497",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7\n"
     ]
    }
   ],
   "source": [
    "mean_x = round(sum(x) / len(x), 1)\n",
    "print(mean_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8799761e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can solve the median problem (approximately) by sorting the list, and getting the value that is halfway through the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37ba2b1d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5\n"
     ]
    }
   ],
   "source": [
    "x.sort()\n",
    "median = x[int(len(x) / 2)]\n",
    "print(median)\n",
    "\n",
    "# must first SORT the list and grab the middle value (by definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceca96fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is also simple to get the min and max, using built-in list indexes to get the first and last element from the sorted list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6bf9b77",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_x = x[0]\n",
    "min_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ffc4a05",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_x = x[-1]\n",
    "max_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e2a3cd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "OK, this is progress.  Can we now do other math on the data, like multiply each value by 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa48ffa6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7, 0.8, 1.2, 3.3, 3.9, 4.5, 4.7, 4.8, 5.3, 5.4, 5.9, 0.7, 0.8, 1.2, 3.3, 3.9, 4.5, 4.7, 4.8, 5.3, 5.4, 5.9, 0.7, 0.8, 1.2, 3.3, 3.9, 4.5, 4.7, 4.8, 5.3, 5.4, 5.9, 0.7, 0.8, 1.2, 3.3, 3.9, 4.5, 4.7, 4.8, 5.3, 5.4, 5.9, 0.7, 0.8, 1.2, 3.3, 3.9, 4.5, 4.7, 4.8, 5.3, 5.4, 5.9]\n"
     ]
    }
   ],
   "source": [
    "y = x * 5\n",
    "print(y)\n",
    "# do not want 5 repeats of the same list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3608cb9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Not what we wanted. That just concatenated 5 copies of the list together! Let's try a different approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60b1c37b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.5, 4.0, 6.0, 16.5, 19.5, 22.5, 23.5, 24.0, 26.5, 27.0, 29.5]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = []\n",
    "for item in range(len(x)):\n",
    "    y.append(x[item] * 5)\n",
    "y\n",
    "\n",
    "# to multiply list by integer: must iterate over every item in the list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b311a8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Alright, this is a big improvement over the iteration-by-rows approach, but it still a bit tedious, especially if we had a much larger list of items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c98f78b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.1.3 Vectorization: an Alternative to Iteration\n",
    "\n",
    "**Vectorization** is a more computationally efficient approach to performing repeated operations over a sequence of data. Rather than having Python perform an operation on one item at a time until it reaches the end of the sequence, we can tell Python to do it all at once. This is vast oversimplification of what's actually going on behind the scenes when we employ vectorization, but its close enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba7c848",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In Python, vectorization is made possible through the use of a data type called an `array`, which is defined by the NumPy library. We'll take a closer look at NumPy arrays in a minute, but for now let's admire how they allow us to perform the same exact analysis we just did without ever having to use a for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26d185ce",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7\n",
      "4.5\n",
      "0.7\n",
      "5.9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "rain = np.array(x)\n",
    "print(round(np.mean(rain),1))\n",
    "print(np.median(rain))\n",
    "print(np.min(rain))\n",
    "print(np.max(rain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873a4677",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Much easier than coding for loops and counters, don't you think?  And a lot faster on large datasets, too. In addition to vectorization, NumPy provides us with access to more complex mathematical operations like variance and standard deviation, and integrates nicely with the most common plotting libraries you'll use in Python.\n",
    "\n",
    "Let's look at a sorted list of the elements in the array as a percentage of total rainfall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85c7c402",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11d00fa30>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(np.sort(rain) / np.sum(rain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1a01c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.2 The Python Scientific Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1606ef7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "NumPy and Matplotlib are key components of what is commonly referred to as the **Python Scientific Stack**, which includes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f710c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- NumPy\n",
    "- SciPy\n",
    "- Matplotlib\n",
    "- Scikit-learn\n",
    "- IPython\n",
    "- pandas\n",
    "- Jupyter\n",
    "- Dask\n",
    "- NetworkX\n",
    "- Ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ce7bd2",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.3 NumPy Arrays\n",
    "\n",
    "The **array** is the data type which underpins nearly all scientific computing in Python. Arrays are formally defined in the **NumPy** library, and since NumPy is not a built-in module (like `math` for example), the `array` is not a built-in data type. This means we have to install NumPy and then import it in order to use it and its many methods. Fortunately, the version of Python you installed from Anaconda came with NumPy pre-installed, so the following `import` statement should work without you having to do anything more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc2bdb43",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np  # we \"alias\" (abbreviate) numpy with \"np\" to make it easier to call it later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6ebbf9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If Python tells you that it can't find the NumPy module when you run the cell above, you'll have to install it yourself. To do that, use the following instructions:\n",
    "\n",
    "1. Open up a bash terminal\n",
    "2. Activate the right conda environment using `conda activate <env name>`. By default this is `base`.\n",
    "3. Run `conda install numpy`\n",
    "4. Restart your Juypter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e5354a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.3.1 Install vs Import\n",
    "\n",
    "Nearly all of the Python libraries for scientific computing are designed to work with arrays. This makes NumPy a **dependency** of each of them. In other words, you cannot import those other libraries unless you already have NumPy **installed** in your Python environment. This is because as soon as you do `import scipy` for example, SciPy is going to do `import numpy` behind the scenes. This means you do not need to import NumPy yourself everytime you want to use SciPy; it just needs to be _installed_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b388ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.3.2 Arrays vs. Lists\n",
    "\n",
    "Arrays look a lot like `list` types, but don't be fooled: they are much more powerful. In general, an `array` allows you to _vectorize_ your calculations instead of iterating over a list and applying an operation element by element. Although they are convenient and readable, _for loops are very slow_. Especially when datasets are large, the **computational efficiency** gained by using vectorized calculations can be significant. In addition to speed, arrays are a convenient data structure for implementing the numerical methods from linear algebra and statistics which comprise the majority of applications of scientific computing applications used in data science.\n",
    "\n",
    "Let's start by creating a list, and then creating an array from that list.  Then let's compare how the list of integers works compared to the array.\n",
    "\n",
    "Allows us to perform vectorized operations on lists\n",
    "We will create lists from arrays\n",
    "Vectorization is all about computational efficiency (esp. with huge data sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50186059",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = list(range(1, 6))\n",
    "y = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67055079",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecfaf3a2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y)\n",
    "y\n",
    "# without print statement, y returns with \"array\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d50f6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These two objects x and y look almost the same ... but they are not when it comes to more complex operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f300046",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a9242c8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd02dd7e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see how we can do math operations on these two versions of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c42b5df",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "892065cf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1188799f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1ff3da4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1848ad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So far so good -- not easy to tell the difference between lists and arrays...but we haven't really gotten NumPy involved yet. Let's see how we might use NumPy to perform some operations beyond the simply min/max/sum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf205cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In some cases, we can use a Numpy method and apply it to a list of numbers like we have in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0daeb609",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7be9a26b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03eb0634",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e93c7f2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49d8129a",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0fae979",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "708f3ed4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.3, 0.4, 0.5])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd0c2602",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wq/t7rcncjj6s956tl_y8_y18080000gn/T/ipykernel_54938/3255961832.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "x / 10\n",
    "# ERROR similar to the x * 5 issue, Python doesn't know how to divide a list by an integer\n",
    "# Numpy known that if you have an array, you may want to operate on each item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0e0c83",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "When you apply the `/` operator to an `array`, NumPy knows that you want to divide each element rather than the array itself. Python will not make this same assumption for a `list` type. To perform the same operation on a list, we'd have to use iteration:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae549174",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "xscaled = [z / 10 for z in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc11bebc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For arrays/lists as small as these, the advantage of vectorization might not seem obvious. Maybe bigger objects and more complex operations might make it more clear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45a62030",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = list(range(1, int(1e6)))  # 1 million numbers\n",
    "y = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94484a4f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 491 ms, sys: 33.9 ms, total: 525 ms\n",
      "Wall time: 541 ms\n"
     ]
    }
   ],
   "source": [
    "%time xscaled = [(z ** 2)/ 10 for z in x]\n",
    "# time it takes to perform an operation (iterating over x, square item & didive by 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ade15e2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.2 ms, sys: 3.53 ms, total: 10.7 ms\n",
      "Wall time: 8.67 ms\n"
     ]
    }
   ],
   "source": [
    "%time yscaled = (y ** 2) / 10\n",
    "#same operation Vectorized\n",
    "# wait time 540 ms --> 19ms is a HUGE impact by order of magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c54c91c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "36 times faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89eef19",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.3.3 Working with Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ec348",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The easiest ways to create arrays:\n",
    "1. Convert a list:\n",
    "```\n",
    "np.array([1, 2, 3])\n",
    "```\n",
    "2. Initialize an array of the shape you want filled with all zeros or all ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3f8ec1d",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "Z = np.zeros(10)\n",
    "print(Z)\n",
    "# With vectorization, we gain speed BUT Python needs to know the exact shape ahead of time so it can operate \n",
    "# across the data set simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ed2cf6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And we can set values in the arrays by index value -- meaning they are **mutable**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1504c8b5",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "Z[4] = 1\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc39911",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Arrays are not always simple one-dimensional arrays like a column in a spreadsheet.  They could be 2 dimensional like a table, or 3 dimensional like a set of tables, or many dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2c42cc1",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = np.arange(9).reshape(3, 3)\n",
    "Z\n",
    "# numpy version of range is \"arange\" (array range) \n",
    "# np.arange(9) is range 0-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75ba8867",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wq/t7rcncjj6s956tl_y8_y18080000gn/T/ipykernel_54938/2348642517.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# returns all items in second column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# returns all items from third column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# [<row index>, <column index>]\n",
    "Z[1]  # returns all items in second column\n",
    "Z[:2] # returns all items from third column\n",
    "np.sum[1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d719d6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`np.arange()`? `np.reshape()`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e366c61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Of course if you have a 2-dimensional array, your indexing into the array becomes two dimensional as well, with row, then column index values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6bd2095",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 9],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z[0, 2] = 9\n",
    "Z\n",
    "# first row # third column. Value updated = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbe8f43",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7166e0",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Z.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e3b258",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You might or might not have noticed that when we do calculations on arrays like adding two arrays together, the default behavior is element by element.  Look at thr result of adding Z to itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5cad9063",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2, 18],\n",
       "       [ 6,  8, 10],\n",
       "       [12, 14, 16]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z + Z\n",
    "# adding arrays will add them element + element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7680c01a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Or multiplying it by itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77f8ceaf",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1, 81],\n",
       "       [ 9, 16, 25],\n",
       "       [36, 49, 64]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z * Z\n",
    "# pairwise multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac850a42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this example we create a 10 x 10 array of random numbers and find the min and max of the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29e22647",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011294333490560304 0.9986650553520738\n"
     ]
    }
   ],
   "source": [
    "Z = np.random.random((10, 10))\n",
    "Zmin, Zmax = Z.min(), Z.max()\n",
    "print(Zmin, Zmax)\n",
    "\n",
    "\n",
    "# generate random numbers, return min & max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adda0b0d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Some NumPy operations are available as array methods. But others are only defined as NumPy functions, like median and percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba7b22b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(np.mean(Z))  # function\n",
    "print(Z.mean())  # method. already initialized the opbect --> don't need \"self\" referencw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a938dfb2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(np.median(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a2861a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(Z.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad60a22",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remember this example from the first class?  It was using Numpy arrays and the Matplotlib library for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2857a482",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeea5a2",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "y = np.sin(x)\n",
    "plt.plot(x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7131786",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.3.4 Numpy for Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2007ce9a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If you have used a program like Matlab, R, Gauss, Octave or any other matrix - based language for doing linear algebra or statistics, this is not what you expect.  Instead, multiplying two matrices would be expected to produce a dot product, or matrix multiplication.  NumPy can do that too, but it just uses a different syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de8c3259",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "Z = np.arange(9).reshape(3, 3)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cdec4d9b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 15,  18,  21],\n",
       "       [ 42,  54,  66],\n",
       "       [ 69,  90, 111]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.dot(Z)\n",
    "# Matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ca8c4e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can also do a matrix transpose (switching axes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e1fc5bbf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.array(Z.T == Z.T))\n",
    "# Z.T is the functional form of writing the same thing\n",
    "# this mech checks if each item matches (transposes) correctly onto other value\n",
    "\n",
    "# TRANSPOSE is the more efficient mechanism that checks if entire array matches\n",
    "print(np.array_equal(np.transpose(Z), Z.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9f2fca",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And easily compute an identity matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f856fc0",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.eye(3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0e3a6a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.3.5 Numpy Summary\n",
    "\n",
    "NumPy is a very powerful multi-dimensional array processing library for Python, and it is very fast because the underlying implementation is actually in the C programming language.\n",
    "\n",
    "The Scientific Python ecosystem we will be using in this course uses NumPy heavily, but usually it is \"under the hood\", and we use it through the Pandas library which makes it much easier to use and to handle data as tables.  But you might find significant value in learning more about NumPy if you need lower level functionality or want to code something very computationally intensive. It is not expected that you use it heavily in this course, however.\n",
    "\n",
    "As we will learn later in the course, we can use the NumPy multi-dimensional array library and other libraries built on it to do statistical analysis and machine learning. NumPy solves one of the main limitations of the Python language, which is that it is very slow at iterating or looping through calculations once the size of the data becomes large. But NumPy does those same operations very efficiently by using vectorized computation. For example, it multiplies two arrays all at once rather than looping through each row and multiplying the elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64596c02",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.3.6 Exercise\n",
    "\n",
    "Now do some experimenting with Numpy to get more familiar with it.\n",
    "\n",
    "Try creating a 100 x 100 element array with random numbers\n",
    "\n",
    "Multiply those by 2\n",
    "\n",
    "Calculate the 75% percentile value of the array\n",
    "\n",
    "Calculate minimum, maximum, median, and 10th and 90th percentile values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4fb375",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52c18206",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.4 Graphing with `matplotlib`\n",
    "The `matplotlib` library includes a variety of functions that allow us to build plots of data. There are lots of different data viz libraries in Python we'll be exploring later, but most of them are built on top of Matplotlib (kind of like NumPy for data analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ed310e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " Once again, you must first import the library before you can use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34f0ee5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # import matplotlib\n",
    "%matplotlib inline   # display to nicely in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbb7441",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Before you can use the plotting functions, you must first have some data to plot. Below are some data on Berkeley restaurants taken from Yelp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806cadbc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "restaurants = [\"Gypsy's\", \"Tacos Sinaloa\", \"Sliver\", \"Muracci's\", \"Brazil Cafe\", \"Thai Basil\"]\n",
    "rating = [4, 4, 4, 3.5, 4.5, 3.5]\n",
    "number_of_ratings = [1666, 347, 1308, 294, 1246, 904]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c7fc4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You may be interested in seeing if there is a relationship between the number of ratings a restaurant has and their rating out 5 stars. It is difficult to determine this from looking at the numbers directly, so a plot can come in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eaf6ec",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(number_of_ratings, rating)  # create a scatter plot\n",
    "plt.show()  # show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bc2982",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Out of context, this plot is not very helpful because it doesn't have axis labels or a title. These components can be added using other `matplotlib` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20093f7a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(number_of_ratings, rating)  # create a scatter plot\n",
    "plt.xlabel(\"Number of Ratings\")  # add the x-axis label\n",
    "plt.ylabel(\"Star Rating (out of 5)\")  # add the y-axis label\n",
    "plt.title(\"Berkeley Restaurant Star Ratings by Number of Ratings\")  # add a title\n",
    "plt.show()  # show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed843cc5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are many other attributes you can add to plots and many more types of plots you can create using this library. For a comprehensive description, visit the [documentation](https://matplotlib.org/api/pyplot_api.html)! Included here are some basic plots that you may find useful for this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0dd869",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# create a bar plot\n",
    "plt.bar(restaurants, number_of_ratings)\n",
    "\n",
    "# add the x-axis label\n",
    "plt.xlabel(\"Restaurant\")\n",
    "\n",
    "# add the y-axis label\n",
    "plt.ylabel(\"Number of Ratings\")\n",
    "\n",
    "# add a title\n",
    "plt.title(\"Berkeley Restaurant Star Ratings\")\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14181f20",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# create a histogram\n",
    "plt.hist(rating)\n",
    "\n",
    "# add the x-axis label\n",
    "plt.xlabel(\"Star Rating (out of 5)\")\n",
    "\n",
    "# add the y-axis label\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# add a title\n",
    "plt.title(\"Berkeley Restaurant Star Rating Frequencies\")\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d65d84",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is also possible to overlay multiple lines on a single plot. Below are some made up data about the number of people with each height in two different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c05e7d41",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "height = [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72]\n",
    "class_one = [1, 1, 0, 3, 7, 4, 3, 7, 8, 3, 1, 2, 1]\n",
    "class_two = [0, 0, 3, 1, 3, 4, 1, 2, 6, 2, 8, 5, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c741df4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can use the `.plot()` function to plot both of these functions as line plots. If you run multiple calls to plotting functions in the same cell, Python will simply layer the resulting plots on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad07dd5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# create a line plot for the first class\n",
    "# label this line as class one for the legend\n",
    "plt.plot(height, class_one, label = \"class one\")\n",
    "\n",
    "# create a line plot for the second class\n",
    "# label this line as class two for the legend\n",
    "plt.plot(height, class_two, label = \"class two\")\n",
    "\n",
    "# add the x-axis label\n",
    "plt.xlabel(\"Height (in)\")\n",
    "\n",
    "# add the y-axis label\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# add the legend\n",
    "plt.legend()\n",
    "\n",
    "# add the title\n",
    "plt.title(\"Frequencies of Different Heights for Two Classes\")\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c6d92a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.5 Intro to pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbad2e1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`pandas` is the most popular library for doing data analysis in Python. The Wes McKinney book you've been reading is basically just a guide to Pandas. I wince every time I have to say the word \"pandas\" because I think it's a dumb name, but I wind up having to wince a lot because it is so fundamental to what I use Python for on a day-to-day basis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fdb893",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Just like NumPy, we'll import pandas and give it the alias `pd`. This is just convention. You could give it any alias you like, or no alias at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c83336ba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c012a516",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.5.1 The `pandas` data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76fe8d0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "The pandas library provides us with two new data types, both of which are built on the NumPy `array`:\n",
    "1. `pandas.Series`: a 1d named array with a named index.\n",
    "2. `pandas.DataFrame`: a 2d array (table) of `pandas.Series` columns which share a named index.\n",
    "\n",
    "Allows us to index rows and columns.\n",
    "Each column in a data frame is a series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6d2de5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`Series` objects are basically dictionaries, where the keys are now an index and the values are an array of all the same type. A `DataFrame` is like a table where the values are a 2d array or matrix and each column is comprised of a `Series`.\n",
    "\n",
    "You can create a `Series` from a list or a DataFrame from a list of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "08ad2409",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person_0     60\n",
       "person_1     61\n",
       "person_2     62\n",
       "person_3     63\n",
       "person_4     64\n",
       "person_5     65\n",
       "person_6     66\n",
       "person_7     67\n",
       "person_8     68\n",
       "person_9     69\n",
       "person_10    70\n",
       "person_11    71\n",
       "person_12    72\n",
       "Name: height, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height = [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72]\n",
    "class_one = [1, 1, 0, 3, 7, 4, 3, 7, 8, 3, 1, 2, 1]\n",
    "class_two = [0, 0, 3, 1, 3, 4, 1, 2, 6, 2, 8, 5, 2]\n",
    "\n",
    "pd.Series(height, index=['person_' + str(i) for i in range(len(height))], name='height')\n",
    "\n",
    "# Can take the heights and turn them into a series by indexing each value with a string\n",
    "# Uses string formatting + list comprehension\n",
    "# Using length(height) as an iterator. Convert integer to a string and append it to \"person_\"\n",
    "# Creates somewhat of a dictionary that maps people (keys) to heights (values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bf68e641",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_0</th>\n",
       "      <th>person_1</th>\n",
       "      <th>person_2</th>\n",
       "      <th>person_3</th>\n",
       "      <th>person_4</th>\n",
       "      <th>person_5</th>\n",
       "      <th>person_6</th>\n",
       "      <th>person_7</th>\n",
       "      <th>person_8</th>\n",
       "      <th>person_9</th>\n",
       "      <th>person_10</th>\n",
       "      <th>person_11</th>\n",
       "      <th>person_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>60</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_one</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_two</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           person_0  person_1  person_2  person_3  person_4  person_5  \\\n",
       "height           60        61        62        63        64        65   \n",
       "class_one         1         1         0         3         7         4   \n",
       "class_two         0         0         3         1         3         4   \n",
       "\n",
       "           person_6  person_7  person_8  person_9  person_10  person_11  \\\n",
       "height           66        67        68        69         70         71   \n",
       "class_one         3         7         8         3          1          2   \n",
       "class_two         1         2         6         2          8          5   \n",
       "\n",
       "           person_12  \n",
       "height            72  \n",
       "class_one          1  \n",
       "class_two          2  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    [height, class_one, class_two],\n",
    "    index=['height','class_one', 'class_two'],\n",
    "    columns=['person_' + str(i) for i in range(len(height))]\n",
    "    )\n",
    "# creating data frame built on all 3 of those lists\n",
    "# Rows/columns can be interchangeable --> add <.T> to switch row to column values & vice versa (below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ac8c2ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>class_one</th>\n",
       "      <th>class_two</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>person_0</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_1</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_2</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_3</th>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_4</th>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_5</th>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_6</th>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_7</th>\n",
       "      <td>67</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_8</th>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_9</th>\n",
       "      <td>69</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_10</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_11</th>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_12</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           height  class_one  class_two\n",
       "person_0       60          1          0\n",
       "person_1       61          1          0\n",
       "person_2       62          0          3\n",
       "person_3       63          3          1\n",
       "person_4       64          7          3\n",
       "person_5       65          4          4\n",
       "person_6       66          3          1\n",
       "person_7       67          7          2\n",
       "person_8       68          8          6\n",
       "person_9       69          3          2\n",
       "person_10      70          1          8\n",
       "person_11      71          2          5\n",
       "person_12      72          1          2"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    [height, class_one, class_two],\n",
    "    index=['height','class_one', 'class_two'],\n",
    "    columns=['person_' + str(i) for i in range(len(height))]).T\n",
    "# TRANSPOSED (.T) version of above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffe9fb5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.5.2 Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581f3e18",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Typically, however, we'll create DataFrames by reading in data that is already in a tabular format, like a .csv. Let's look at our rain data again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7bd76bb9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/rain.csv')\n",
    "# allows us to read file and put it directly into a DATA FRAME (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2714f527",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Notice a few things that have happened here.\n",
    "\n",
    "1. `pd.read_csv()` had enough built-in smarts to read the first row of the file as a header.\n",
    "1. It then read all rows in the file at once to create a table of NumPy arrays.\n",
    "1. It created an automatic unique index, beginning with zero.\n",
    "1. It inferred the type of each variable from the data.\n",
    "\n",
    "Let's explore this pandas `DataFrame` to learn some of its features. Note that a pandas Series is like one column of this DataFrame, coupled with its own index column. So the main difference between a Series and a DataFrame is that the latter has multiple columns. Columns can be of different data types, but within a column, must be consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dfd95bfc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_2014</th>\n",
       "      <th>rainfall_inches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jan</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feb</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mar</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apr</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>may</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  month_2014  rainfall_inches\n",
       "0        jan              5.3\n",
       "1        feb              5.4\n",
       "2        mar              4.8\n",
       "3        apr              4.7\n",
       "4        may              3.3"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "# automatically recognized first row as headers, knows to create an index, inferred and assigned data types of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7dc1b5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "65cde875",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['month_2014', 'rainfall_inches'], dtype='object')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c4a368a2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month_2014          object\n",
       "rainfall_inches    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522aa287",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can select subsets of the rows by indexing, and select specific columns by their name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3c810114",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5.3\n",
       "1    5.4\n",
       "2    4.8\n",
       "3    4.7\n",
       "4    3.3\n",
       "5    1.2\n",
       "Name: rainfall_inches, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rainfall_inches'][:6]\n",
    "# compound indexing\n",
    "# first get rainfall_inches column THEN return first 6 rows\n",
    "# usual connvention is (row, column) BUT for here the COLUMN INDEX comes first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0586588",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can get all of our statistics on the rainfall_inches column in one short command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "89cf209c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11.000000\n",
       "mean      3.681818\n",
       "std       1.923444\n",
       "min       0.700000\n",
       "25%       2.250000\n",
       "50%       4.500000\n",
       "75%       5.050000\n",
       "max       5.900000\n",
       "Name: rainfall_inches, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rainfall_inches'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27afd389",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice how it silently handled the missing value for September and gave the correct statistical results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbb66b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can also get these values 'a la carte'.  You might recognize that these are essentially NumPy functions which Pandas has provided access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61daaadf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['rainfall_inches'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f046593f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['rainfall_inches'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8e80a49e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rainfall_inches.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80c2662",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Notice that there is some flexibility in syntax, with multiple ways to perform certain operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9f6f8868",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rainfall_inches'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b9bd07",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.rainfall_inches.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d57db4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.min(df.rainfall_inches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0a234b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pandas also provides access to some of the basic functionality of `matplotlib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "86dfadb8",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='month_2014'>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(y = 'rainfall_inches', x = 'month_2014')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9184a63c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.5.3 Slicing and Selecting Data\n",
    "\n",
    "#### 2.5.3.1 Indexing\n",
    "\n",
    "pandas provides two indexing methods for getting slices of rows and columns from your data: `loc` and `iloc`. Both of them use the same square bracket notation you should be used to by now:\n",
    "\n",
    "```\n",
    "[<row index>, <column index>]\n",
    "```\n",
    "\n",
    "The `iloc` method lets you index a pandas `DataFrame` like indexing a 2d NumPy `array`, using integers to represent the _positions_ of rows and columns:\n",
    "\n",
    "iloc (integer loc) & loc are 2 critical indexing methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1354d81b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_2014</th>\n",
       "      <th>rainfall_inches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jan</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feb</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mar</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apr</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>may</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jun</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  month_2014  rainfall_inches\n",
       "0        jan              5.3\n",
       "1        feb              5.4\n",
       "2        mar              4.8\n",
       "3        apr              4.7\n",
       "4        may              3.3\n",
       "5        jun              1.2"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0:6, 0:2]\n",
    "# first 6 rows & first 2 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afe0bca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The `loc` method lets us use the index _labels_ to get data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6f79c87f",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_2014</th>\n",
       "      <th>rainfall_inches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jan</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feb</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mar</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apr</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>may</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jun</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jul</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  month_2014  rainfall_inches\n",
       "0        jan              5.3\n",
       "1        feb              5.4\n",
       "2        mar              4.8\n",
       "3        apr              4.7\n",
       "4        may              3.3\n",
       "5        jun              1.2\n",
       "6        jul              0.8"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0:6, :'rainfall_inches']\n",
    "# Label-based indexing goes UP TO & INCLUDING the labels we input\n",
    "# loc uses actual row/column labels rather than positional indexes\n",
    "# get all rows where LABEL matches these values 0-6 (up to AND INCLUDING), AND all columns UP TO & INCLUDING 'rainfall'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7fa9fc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since `loc` does not use positional indexing, notice how the rules of positional indexing do not apply."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3b182f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That's right, label-based slicing is **endpoint inclusive**. More on this [here](https://pandas.pydata.org/docs/user_guide/advanced.html#advanced-endpoints-are-inclusive)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c306521",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sometimes it's useful to give your index a meaningful name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c526d8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.index.name = 'obs_id'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eea6e1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 2.5.3.2 Boolean Indexing\n",
    "\n",
    "You can easily filter rows of a dataframe by applying one or more boolean expressions to values in one or more columns. Below we filter `df` to select only months with less than 4 inches of rainfall.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1e1adeff",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_2014</th>\n",
       "      <th>rainfall_inches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>may</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jun</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jul</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aug</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>oct</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  month_2014  rainfall_inches\n",
       "4        may              3.3\n",
       "5        jun              1.2\n",
       "6        jul              0.8\n",
       "7        aug              0.7\n",
       "9        oct              3.9"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['rainfall_inches'] < 4]\n",
    "# BOOLEAN MASKING\n",
    "# can use Boolean to return only the rows of data that return True/False\n",
    "# return all rows in df where rainfall < 4\n",
    "# Without the nested df, it will produce just a boolean df filled with T/F values\n",
    "# nested df produces data frame that meets the boolean condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e7f0c5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4      True\n",
       "5      True\n",
       "6      True\n",
       "7      True\n",
       "8     False\n",
       "9      True\n",
       "10    False\n",
       "11    False\n",
       "Name: rainfall_inches, dtype: bool"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rainfall_inches'] < 4\n",
    "# un-nested example of above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e98d45",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice the nested use of df.  What happens if you don't do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d39b9b3",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['rainfall_inches'] < 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2772e39f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can also select rows based on the values of more than one column.  Just remember to nest the individual conditions within parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f093522",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df[(df['month_2014'] == 'jan') & (df['rainfall_inches'] > 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58984159",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "pandas lets us get pretty fancy with our boolean expressions to extract exactly the data we want from our table.\n",
    "\n",
    "For example, we can filter based on string matching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5348e384",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_2014</th>\n",
       "      <th>rainfall_inches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jan</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jun</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jul</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  month_2014  rainfall_inches\n",
       "0        jan              5.3\n",
       "5        jun              1.2\n",
       "6        jul              0.8"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['month_2014'].str.contains('j')]  # more on this later\n",
    "# (look at Pandas for working with strings)\n",
    "# return all months in which the string contains letter 'j'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ad251",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can filter out missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "421c12d8",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_2014</th>\n",
       "      <th>rainfall_inches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jan</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feb</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mar</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apr</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>may</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jun</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jul</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aug</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>oct</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nov</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dec</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_2014  rainfall_inches\n",
       "0         jan              5.3\n",
       "1         feb              5.4\n",
       "2         mar              4.8\n",
       "3         apr              4.7\n",
       "4         may              3.3\n",
       "5         jun              1.2\n",
       "6         jul              0.8\n",
       "7         aug              0.7\n",
       "9         oct              3.9\n",
       "10        nov              4.5\n",
       "11        dec              5.9"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['rainfall_inches'].notnull()]\n",
    "# return only rows that are not null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea5e04",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Or do the opposite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ec768ae1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_2014</th>\n",
       "      <th>rainfall_inches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sep</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  month_2014  rainfall_inches\n",
       "8        sep              NaN"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['rainfall_inches'].isnull()]\n",
    "# return only rows that are null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7758e1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's say we know that the value for \"sep\" should be 2.5. We can use `loc` to perform assignment in pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "53850c9d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_2014</th>\n",
       "      <th>rainfall_inches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [month_2014, rainfall_inches]\n",
       "Index: []"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['month_2014'] == 'sep', 'rainfall_inches'] = 2.5  # boolean row-index + label-based col index\n",
    "df[df['rainfall_inches'].isnull()]\n",
    "\n",
    "#use loc for VARIABLE ASSIGNMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f776ebd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_2014</th>\n",
       "      <th>rainfall_inches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [month_2014, rainfall_inches]\n",
       "Index: []"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['rainfall_inches'].isnull()]\n",
    "\n",
    "# we updated the previous null item --> no more null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de73a72",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If we want to preserve this change, we can save the DataFrame to to disk as a new .csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6cdf2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('data/rain_updated.csv', index=False)\n",
    "# updates to local copy of file, rather than computer memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b78e79",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.5.4 String functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebd1f08",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We briefly saw an example of string matching above. pandas comes with a number of very powerful functions more operating on `str` type Series. Let's investigate them using some California Census data I've already prepared for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2a443fec",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ca_tracts_pop_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dc989503",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POPGROUP</th>\n",
       "      <th>label</th>\n",
       "      <th>GEOIDLONG</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>geodisplay</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Total population</td>\n",
       "      <td>1400000US06001400100</td>\n",
       "      <td>6001400100</td>\n",
       "      <td>Census Tract 4001, Alameda County, California</td>\n",
       "      <td>2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Total population</td>\n",
       "      <td>1400000US06001400200</td>\n",
       "      <td>6001400200</td>\n",
       "      <td>Census Tract 4002, Alameda County, California</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Total population</td>\n",
       "      <td>1400000US06001400300</td>\n",
       "      <td>6001400300</td>\n",
       "      <td>Census Tract 4003, Alameda County, California</td>\n",
       "      <td>4865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Total population</td>\n",
       "      <td>1400000US06001400400</td>\n",
       "      <td>6001400400</td>\n",
       "      <td>Census Tract 4004, Alameda County, California</td>\n",
       "      <td>3703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Total population</td>\n",
       "      <td>1400000US06001400500</td>\n",
       "      <td>6001400500</td>\n",
       "      <td>Census Tract 4005, Alameda County, California</td>\n",
       "      <td>3517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   POPGROUP             label             GEOIDLONG       GEOID  \\\n",
       "0         1  Total population  1400000US06001400100  6001400100   \n",
       "1         1  Total population  1400000US06001400200  6001400200   \n",
       "2         1  Total population  1400000US06001400300  6001400300   \n",
       "3         1  Total population  1400000US06001400400  6001400400   \n",
       "4         1  Total population  1400000US06001400500  6001400500   \n",
       "\n",
       "                                      geodisplay  Population  \n",
       "0  Census Tract 4001, Alameda County, California        2937  \n",
       "1  Census Tract 4002, Alameda County, California        1974  \n",
       "2  Census Tract 4003, Alameda County, California        4865  \n",
       "3  Census Tract 4004, Alameda County, California        3703  \n",
       "4  Census Tract 4005, Alameda County, California        3517  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3854073b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's create a new column, called \"state\", and populate it by getting the last element in the \"geodisplay\" field. This is a very common type of data processing you might need to do on data you acquire for your own projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3b6720de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.sample of       POPGROUP             label             GEOIDLONG       GEOID  \\\n",
       "0            1  Total population  1400000US06001400100  6001400100   \n",
       "1            1  Total population  1400000US06001400200  6001400200   \n",
       "2            1  Total population  1400000US06001400300  6001400300   \n",
       "3            1  Total population  1400000US06001400400  6001400400   \n",
       "4            1  Total population  1400000US06001400500  6001400500   \n",
       "...        ...               ...                   ...         ...   \n",
       "7995         1  Total population  1400000US06115040800  6115040800   \n",
       "7996         1  Total population  1400000US06115040901  6115040901   \n",
       "7997         1  Total population  1400000US06115040902  6115040902   \n",
       "7998         1  Total population  1400000US06115041000  6115041000   \n",
       "7999         1  Total population  1400000US06115041100  6115041100   \n",
       "\n",
       "                                         geodisplay  Population  \n",
       "0     Census Tract 4001, Alameda County, California        2937  \n",
       "1     Census Tract 4002, Alameda County, California        1974  \n",
       "2     Census Tract 4003, Alameda County, California        4865  \n",
       "3     Census Tract 4004, Alameda County, California        3703  \n",
       "4     Census Tract 4005, Alameda County, California        3517  \n",
       "...                                             ...         ...  \n",
       "7995      Census Tract 408, Yuba County, California        4233  \n",
       "7996   Census Tract 409.01, Yuba County, California        2783  \n",
       "7997   Census Tract 409.02, Yuba County, California        1737  \n",
       "7998      Census Tract 410, Yuba County, California        7357  \n",
       "7999      Census Tract 411, Yuba County, California        4941  \n",
       "\n",
       "[8000 rows x 6 columns]>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample\n",
    "# shows random columns of data to give us a sense of how it looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feef792",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['state'] = df['geodisplay'].str.split(',').str[2]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e4d10b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We use the same approach to add a 'county' column to our dataframe, pulling the values from the geodisplay column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7869c6",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['county'] = df['geodisplay'].str.split(',').str[1].str.replace(' County', '')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb4c111",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now let's see what the full list of unique county names is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8ce76",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['county'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a78bcd1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's create a census tract column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eae643a",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['Tract'] = df['geodisplay'].str.split(',').str[0].str.split().str[2]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d210d7a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Could you have extracted the Tract number from the \"GEOIDLONG\" column instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d40316",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['Tract'] = df['GEOIDLONG'].str[-6:-2] + '.' + df['GEOIDLONG'].str[-2:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598aa818",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Can you spot the difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf8bfa4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.5.5 More pandas operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9505b5f2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Summary stats**\n",
    "pandas makes it really easy to quickly summarize and parse your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13530aa2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.head()  # first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ad3232a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POPGROUP</th>\n",
       "      <th>label</th>\n",
       "      <th>GEOIDLONG</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>geodisplay</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7367</th>\n",
       "      <td>1</td>\n",
       "      <td>Total population</td>\n",
       "      <td>1400000US06095250502</td>\n",
       "      <td>6095250502</td>\n",
       "      <td>Census Tract 2505.02, Solano County, California</td>\n",
       "      <td>3128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>1</td>\n",
       "      <td>Total population</td>\n",
       "      <td>1400000US06037532400</td>\n",
       "      <td>6037532400</td>\n",
       "      <td>Census Tract 5324, Los Angeles County, California</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5330</th>\n",
       "      <td>1</td>\n",
       "      <td>Total population</td>\n",
       "      <td>1400000US06071001905</td>\n",
       "      <td>6071001905</td>\n",
       "      <td>Census Tract 19.05, San Bernardino County, Cal...</td>\n",
       "      <td>6389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      POPGROUP             label             GEOIDLONG       GEOID  \\\n",
       "7367         1  Total population  1400000US06095250502  6095250502   \n",
       "2729         1  Total population  1400000US06037532400  6037532400   \n",
       "5330         1  Total population  1400000US06071001905  6071001905   \n",
       "\n",
       "                                             geodisplay  Population  \n",
       "7367    Census Tract 2505.02, Solano County, California        3128  \n",
       "2729  Census Tract 5324, Los Angeles County, California         112  \n",
       "5330  Census Tract 19.05, San Bernardino County, Cal...        6389  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)  # random 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461703f5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1377f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Sorting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceb5e2c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.sort_values(['rainfall_inches'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8012dce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Basic Aggregations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c5957f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['month_2014'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9ef6b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['month_2014'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a1dd7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['month_2014'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e92ee05",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remember, DataFrames are just NumPy arrays with some frills on top. The `array` form is stored as an **attribute** of the DataFrame named \"values\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf8fe97",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(df.values)\n",
    "print(type(df.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261b8074",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Column selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb90ba8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can also easily create a DataFrame from a dictionary. Let's follow an example from the Python for Data Analysis book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "301e6c2b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],\n",
    "    'year': [2000, 2001, 2002, 2001, 2002],\n",
    "    'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}\n",
    "sp = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df37e41",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's investigate the contents of `sp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c3aa3747",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2002</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>2001</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>2002</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    state  year  pop\n",
       "0    Ohio  2000  1.5\n",
       "1    Ohio  2001  1.7\n",
       "2    Ohio  2002  3.6\n",
       "3  Nevada  2001  2.4\n",
       "4  Nevada  2002  2.9"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515d55f5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc61bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.values\n",
    "# gives whole data frame as numpy array\n",
    "# BUT if you have a column named \"values\" square brackets [] help pandas distinguish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654e32d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can refer to a column in two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c32a5d9e",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Ohio\n",
       "1      Ohio\n",
       "2      Ohio\n",
       "3    Nevada\n",
       "4    Nevada\n",
       "Name: state, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp['state']\n",
    "sp.state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb066a3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Generally it is preferable to be explicit and use the `df[<column name>]` approach. Can you imagine why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3596ea62",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What if we had a column named \"values\"? How could pandas distinguish between \"values\" the attribute and \"values\" the column?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42c78bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Iteration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e395f53",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can also iterate through the rows of a dataframes using `iterrows()`. This works a lot like list enumeration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8c190a31",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ohio\n",
      "Ohio\n",
      "Ohio\n",
      "Row 3 is not Ohio\n",
      "Row 4 is not Ohio\n"
     ]
    }
   ],
   "source": [
    "for i, row in sp.iterrows():\n",
    "    if row['state'] == 'Ohio':\n",
    "        print(row['state'])\n",
    "    else:\n",
    "        print('Row {0} is not Ohio'.format(i))\n",
    "\n",
    "# iterate function over each row in a column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d0a4e0",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"https://i.kym-cdn.com/photos/images/original/001/733/249/7a0\" alt=\"drawing\" width=\"25%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb2f028",
   "metadata": {},
   "source": [
    "## 2.6 Exercises\n",
    "\n",
    "### 2.6.1 Pandas expressions\n",
    "Below are a series of questions, with the answers remaining for you to fill in by using pandas expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f082b3",
   "metadata": {},
   "source": [
    "Can you get a profile of a column that is not numeric, like state? Try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffa08bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67df6292",
   "metadata": {},
   "source": [
    "How can we print the data types of each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0b2d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4663182",
   "metadata": {},
   "source": [
    "How can we print just the column containing state names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ee5f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "800baa5d",
   "metadata": {},
   "source": [
    "How can we get a list of the states in the DataFrame, without duplicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938e2d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "876be48b",
   "metadata": {},
   "source": [
    "How can we compute the mean of population across all the rows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6fa796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c29c1f73",
   "metadata": {},
   "source": [
    "How can we compute the maximum population across all the rows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e68a787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e562d2b",
   "metadata": {},
   "source": [
    "How can we compute the 20th percentile value of population? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362fb68a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10f51b24",
   "metadata": {},
   "source": [
    "How can we compute a Boolean array indicating whether the state is 'Ohio'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078ffc19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a966dc5f",
   "metadata": {},
   "source": [
    "How can we select and print just the rows for Ohio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c220a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1191112",
   "metadata": {},
   "source": [
    "How can we create a new DataFrame containing only the Ohio records?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca46404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ffdd32c",
   "metadata": {},
   "source": [
    "How can we select and print just the rows in which population is more than 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd45250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04ac9ea8",
   "metadata": {},
   "source": [
    "How could we compute the mean of population that is in Ohio, averaging across years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a94689a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf708513",
   "metadata": {},
   "source": [
    "How can we print the DataFrame, sorted by State and within State, by Population?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da301d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "824c5452",
   "metadata": {},
   "source": [
    "How can we print the row for Ohio, 2002, selecting on its values (not on row and column indexes)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64da333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "595092b0",
   "metadata": {},
   "source": [
    "How can we use row and column indexing to set the population of Ohio in 2002 to 3.4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81974332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b12d547",
   "metadata": {},
   "source": [
    "### 2.6.2 COVID cases from NY Times\n",
    "\n",
    "We end our intro to pandas with a quick look at how easy it is to load data into a dataframe. In this case, let's pull data from the New York Times online data for COVID cases, by county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9517226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f5a3b25a",
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 8] nodename nor servname provided, or not known>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[1;32m   1347\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1324\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;34m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m         self.sock = self._create_connection(\n\u001b[0m\u001b[1;32m    946\u001b[0m             (self.host,self.port), self.timeout, self.source_address)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    953\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wq/t7rcncjj6s956tl_y8_y18080000gn/T/ipykernel_54938/3115100179.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muscovid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# can use pandas to read URL of a data file .csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    610\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    535\u001b[0m                                   '_open', req)\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[1;32m   1390\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 8] nodename nor servname provided, or not known>"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv'\n",
    "uscovid = pd.read_csv(url)\n",
    "# can use pandas to read URL of a data file .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ab1ef9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "uscovid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b806b08",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a8ffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cacovid = uscovid[uscovid['state']=='California']\n",
    "cacovid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb0bc85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alameda_covid = cacovid[cacovid['county']=='Alameda']\n",
    "alameda_covid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34920290",
   "metadata": {},
   "source": [
    "Go ahead, experiment with these data - see what you can do with some basic Pandas commands.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc73fcb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4eb4858e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Intro to Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f46b658",
   "metadata": {},
   "source": [
    "## 3.1 Merges and Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447b1202",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Pandas has a very powerful set of methods for merging DataFrames together. This is a very common procedure as it is very rare for all of your data to be stored in a single file. These methods are designed to work like database queries, so the syntax borrows heavily from SQL. If you're unfamiliar with relational algebra/SQL, check out the official pandas [docs](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#brief-primer-on-merge-methods-relational-algebra) for more detail. Let's review them using a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7dc06a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "favorite_numbers = pd.DataFrame([\n",
    "    [\"Boba Fett\", 42],\n",
    "    [\"Boba Fett\", 3.14],\n",
    "    [\"Bossk\", 7],\n",
    "    [\"Bossk\", 9],\n",
    "    [\"IG-88\", 3],\n",
    "    [\"Dengar\", np.NaN]], columns=[\"Name\", \"Number\"])\n",
    "\n",
    "email_addr = pd.DataFrame([\n",
    "    [\"Boba Fett\", \"boba@bountyhunters.com\"],\n",
    "    [\"Bossk\", \"boskk@bountyhunters.com\"],\n",
    "    [\"IG-88\", \"ig88@bountyhunters.com\"],\n",
    "    [\"Dengar\", \"dengar@bountyhunters.com\"],\n",
    "    [\"4-LOM\", \"4lom@bountyhunters.com\"],\n",
    "    [\"Zuckuss\", \"thezuck@bountyhunters.com\"]], columns=[\"Name\", \"Email\"])\n",
    "\n",
    "# want to merge data tables (fav numbers & email addresses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aa2535",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The first table contains favorite numbers of some famous people."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf4064",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"https://www.syfy.com/sites/syfy/files/2020/05/bounty-hunters-esb.jpg\" width=50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b14112",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "favorite_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9666d2df",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The second table contains the individuals email addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1a9622",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "email_addr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8762263",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are actually many ways you could imagine combining data from both of these tables.  In the following we work through a few example methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b61fef5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.1.1 Merge\n",
    "\n",
    "Probably the most general and standard way to join tables in pandas is to use the merge function. There are many ways to do a merge, however, so let's go through them each one by one:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc823d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.1.1.1 Inner merge\n",
    "The default type of `merge` is the **inner** merge, which corresponds to an \"inner join\" in SQL. Each merge type requires you to specify the column(s) on which you are joining. An inner join, however, only returns rows where the `on` value appears in both tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34dd90d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(email_addr, favorite_numbers, on=\"Name\", how=\"inner\")\n",
    "# by default, Python will merge INNER, unless we indicate otherwise via how=\"inner\"\n",
    "# inner --> only returns rows that match the \"on\" key for both tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13be74b9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that Boba Fett and Bossk occur 2 times since each had two favorite numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9c57df",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.1.1.2 Left merge\n",
    "\n",
    "A **left merge** will keep all the entries in the left table even if they have no matching entry in the right table.  For example, we don't have 4-LOM's or Zuckess's favorite numbers, so the inner join simply dropped these rows. With a _left_ join, we preserve all rows from the lefthand table, with unmatched rows appearing as missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c039d99f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(email_addr, favorite_numbers, on=\"Name\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b614bb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a = pd.merge(email_addr, favorite_numbers, on=\"Name\", how=\"left\")\n",
    "b = pd.merge(favorite_numbers, email_addr, on=\"Name\", how=\"right\")\n",
    "all(a.index == b.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d84150",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.1.1.3 Outer Merge\n",
    "\n",
    "The outer join keeps entries in both tables even if they don't have a match in the other and substitutes NaN for missing values. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ef155",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(email_addr, favorite_numbers, on=\"Name\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f27425",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.1.2 Join\n",
    "\n",
    "Pandas also provides a join function which joins two tables on their index.  This function also let's you specify what kind of join you would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706bdf1f",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "favorite_numbers.set_index(\"Name\", inplace=True)\n",
    "email_addr = email_addr.set_index(\"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e67aaae",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "email_addr.join(favorite_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f85849",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note the default join type is `left`, rather than inner. I rarely use `join()` FWIW."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaa01a7",
   "metadata": {},
   "source": [
    "### 3.1.3 More resources to learn about merges and joins\n",
    "\n",
    "These are powerful tools and there are some subtleties in using them.  I recommend doing a fair amount of reading and a lot of practicing to get these ideas and the accompanying syntax internalized into your programming toolkit.\n",
    "\n",
    "Here is another good (and short) tutorial: https://chrisalbon.com/python/pandas_join_merge_dataframe.html\n",
    "\n",
    "And as always, read the docs: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e08793",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.2 Using Merge and `str` ops on Real Data\n",
    "\n",
    "Now that we have some concepts and syntax under control, let's try using them on some larger data tables from the Census, and learn how to use string operations to work with these data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f758d11e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### 3.2.1 Importing County level Census Data for the U.S.\n",
    "\n",
    "Lets say we want to analyze county level population trends. I downloaded two population estimates tables for U.S. Counties and provide them for you here. One contains 2000-2010 data, and the other has 2010-2016.  Lets load them and do some data exploration and manipulation to get a merged county level population series for the 2000 - 2016 period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb97013",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "co00 = pd.read_csv('data/co-est00int-tot.csv', encoding='latin1')\n",
    "co00.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ed430c",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "co16 = pd.read_csv('data/co-est2016-alldata.csv', encoding='latin1')\n",
    "co16.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a15135",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.2.1.1 A note on character encodings\n",
    "One thing that you will encounter as you read data from various sources is that the **character encoding** might be unusual, and require setting the encoding on the read statement.  Full documentation on this is available here:\n",
    "https://docs.python.org/3/library/codecs.html#standard-encodings\n",
    "\n",
    "Some of the most common ones are:\n",
    "\n",
    "- latin1\n",
    "- iso-8859-1\n",
    "- utf_8\n",
    "- utf_16\n",
    "- utf_32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72a4e9d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see what happens when you try loading a csv file with an encoding issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79668c02",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "co00_wrong = pd.read_csv('data/co-est00int-tot.csv')\n",
    "co00_wrong.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76d82ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pandas will try to use `utf-8` to parse your data by default, and if it has trouble it will throw an error and tell you exactly which character caused it. Trying the `latin1` codec is always a good next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458e62f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.2.2 Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23855678",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's look at the columns in our dataframe now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db4eca8",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "list(co16.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32d7e09",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "co16.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c942e9f3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "116 columns!?!  We don't want all of those!  How can we keep just the columns we want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053ecb9d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "co16s = co16.loc[:, :'POPESTIMATE2016']\n",
    "co16s.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2c7507",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ahhh, that's better..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb3c801",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "co16s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99020a54",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But wait... what's going on here?  There seem to be at least two SUMLEV values and it looks suspiciously like there are State level summaries of `POPESTIMATES` embedded in this County-level file.  Let's check how many records there are for each SUMLEV in the file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ed747",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "co16s['SUMLEV'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3cd205",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hmm, OK, so we have 51 SUMLEV 40, which seem to be the State estimates, plus one... let's pull those into a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3ad75f",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "st00 = co00[co00['SUMLEV']==40]\n",
    "st00.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c17e70",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "st00.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2f2e90",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So what is that 51st entry in the set of States?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871681e5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "st00['STNAME'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4123461e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's pull the state records out of the 2016 file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d48952",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "st16 = co16s[co16s['SUMLEV']==40]\n",
    "st16.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaad386",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### 3.2.3 Merging\n",
    "\n",
    "...and merge the 2000 and 2016 data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7406f40",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "stjoin = pd.merge(st00,st16, on='STATE')\n",
    "stjoin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf755a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.2.3.1 Dealing with duplicate columns\n",
    "Looks like it worked! But what are all those columns with `_x` and `_y` suffixes?\n",
    "\n",
    "Seems like a mess to keep all those duplicate columns and have them get renamed like this... what to do...?\n",
    "\n",
    "Maybe we could find the columns that are different in the second dataframe and just add those to the first dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e32fa0",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cols_to_use = list(st16.columns.difference(st00.columns))\n",
    "cols_to_use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c58847",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Anyone have an alternative solution? Maybe one that involves list comprehension?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5188df4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Would it work if we tried to join these two using this as the list of columns from ST16? What about the join column? Seems like that would be pretty handy to have..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f637c56",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cols_to_use.append('STATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8cf0f1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now we can do a much cleaner merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9155e14",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "stjoin2 = pd.merge(st00, st16[cols_to_use], on='STATE')\n",
    "stjoin2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bd6f98",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Looking pretty good.  But there are still a lot of columns we really don't want.  Let's drop those, and set the index to STNAME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44806c66",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "stjoin3 = stjoin2.drop(\n",
    "    ['STATE', 'SUMLEV','REGION','DIVISION','COUNTY','ESTIMATESBASE2000','ESTIMATESBASE2010','CENSUS2010POP','CTYNAME'],\n",
    "    axis=1).copy()\n",
    "stjoin3.set_index('STNAME', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5162ed5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Much nicer.  But I really don't like those column names.  Can't we just make them simple years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548ae8f6",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "stjoin4 = stjoin3.copy()\n",
    "stjoin4.columns = list(range(2000, 2017))\n",
    "stjoin4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d11ac",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Maybe we should write our updated cleaned up data back to a CSV file to reuse later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03d6095",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "stjoin4.to_csv('data/statepop.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64505871",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It might also be handy to transpose the data so that the rows become columns and vice versa.  Let's do that and select just a couple of states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321b3c06",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ST = stjoin4.transpose()\n",
    "ST.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bd898a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Maybe a quick plot of the population trends in these states?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0a034",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ST['California'].plot(figsize=(8, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddc2fd2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.3 More Data Exploration and Cleaning: Berkeley PD Calls\n",
    "\n",
    "Let's load some police call data from the Berkeley Police Department and explore those data... this is an example of having to wrangle some messy, real world data. It's advanced work that you now can handle in Python!\n",
    "\n",
    "For example lets say we want to find out how many vandalism calls there are each day of the week. Let's load some data and figure out how to answer that question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce889cd",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "calls = pd.read_json(\"https://data.cityofberkeley.info/resource/k2nh-s5h5.json\")  # json\n",
    "calls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42654f52",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "calls.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31a1fdf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.3.1 Preliminary observations on the data?\n",
    "\n",
    "1. `eventdt` -- Contain the incorrect time stamp (all the times are 12:00 am)\n",
    "1. `eventtm` -- Contains the time in 24 hour format (What timezone?)\n",
    "1. `indbdate` -- Appears to be correctly formatted and appears awfully consistent in time.\n",
    "1. `block_location` -- Errr, what a mess!  newline characters, and Geocoordinates all merged!!  Fortunately, this field was \"quoted\" otherwise we would have had trouble parsing the file. (why?)\n",
    "1. `blkaddr` -- This appears to be the address in Block Location.\n",
    "1. `city` and `state` seem redundant given this is supposed to be the city of Berkeley dataset.\n",
    "1. `cvdow` almost gives us what we want (\"dow\" == Day of Week), but it would be nice to have the actual day names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ddb878",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.3.2 Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a78a1a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How could we find out how many Vandalism calls happen by day of the week?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c9a318",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "calls['eventdt'] = pd.to_datetime(calls.eventdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c2e466",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "calls['day_of_week'] = calls.eventdt.dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d9d0b3",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "calls.loc[calls['offense'] == 'VANDALISM', 'day_of_week'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cc999f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.3.3 Datetime operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ba3aa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To complete the preceding analysis, we made use of some built-in functionality in pandas for working with dates. The first thing we did was to convert the `eventdt` column from a `str` type to a `datetime` type. Once we have a `datetime` type column, pandas makes it easy to perform all kinds of operations. Note: this syntax should look familiar to you from when we saw `str` type operations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c7a46c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "calls['eventdt'].dt.year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3867339e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "calls['eventdt'].dt.day_of_year.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e51052",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "calls['eventdt'].dt.days_in_month.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258485e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4. For next time \n",
    "- Don't forget "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50b2087",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5. Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8401d76b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Sources\n",
    "\n",
    "This notebook was heavily adapted from previous course material by Prof. Paul Waddell and Samuel Maurer."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "757px",
    "left": "213px",
    "top": "111.133px",
    "width": "206.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
